{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "!pip install opencv-python>=3.4.2.17\n",
    "!pip install libsvm>=3.23.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "from itertools import chain\n",
    "import urllib.request as request\n",
    "import pickle \n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import scipy.signal as signal\n",
    "import scipy.special as special\n",
    "import scipy.optimize as optimize\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import skimage.io\n",
    "import skimage.transform\n",
    "\n",
    "import cv2\n",
    "\n",
    "from libsvm import svmutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Quality Assessment\n",
    "\n",
    "Image quality is a notion that highly depends on observers. Generally, \n",
    "it is linked to the conditions in which it is viewed; therefore, a highly subjective topic. Image quality assessment aims to quantitatively represent the human perception of quality. These metrics commonly are used to analyze the performance of algorithms in different fields of computer vision like image compression, image transmission, and image processing [1].\n",
    "\n",
    "Image quality assessment (IQA) is mainly divided into two areas of research (1) reference-based evaluation and (2)  no-reference evaluation. The main difference is that reference-based methods depend on a high-quality image as a source to evaluate the difference between images. An example of reference-based evaluations is the Structural Similarity Index (SSIM) [2].\n",
    "\n",
    "## No-reference Image Quality Assessment\n",
    "\n",
    "No-reference image quality assessment does not require a base image to evaluate an image quality, the only information that the algorithm receives is the distorted image whose quality is being assessed.\n",
    "\n",
    "Blind methods are mostly comprised of two steps. The first step calculates features that describe the image's structure and the second step relates the features with the human opinion of the image quality. TID2008 is a famous database created following a methodology that describes how to measure human opinion scores from referenced images [3], it is widely used to compare the performance of IQA algorithms.\n",
    "\n",
    "## Blind/referenceless image spatial quality evaluator (BRISQUE)\n",
    "\n",
    "BRISQUE [4] is a model that only used the image pixels to calculate features (other methods are based on image transformation to other spaces like wavelet or DCT). It is demonstrated to be highly efficient as it does not need any transformation to calculate its features.\n",
    "\n",
    "It relies on spatial Natural Scene Statistics (NSS) model of locally normalized luminance coefficients in the spatial domain, as well as the model for pairwise products of these coefficients. \n",
    "\n",
    "## Methodology\n",
    "### Natural Scene Statistics in the Spatial Domain\n",
    "Given an image $I(i, j)$, first, compute the locally normalized luminances $\\hat{I}(i,j)$ via local mean subtraction $\\mu(i,j)$ and divide it by the local deviation $\\sigma(i, j)$. $C$ is added to avoid zero divisions. \n",
    "\n",
    "$$\\hat{I}(i,j) = \\frac{I(i,j) - \\mu(i,j)}{\\sigma(i,j) + C}$$\n",
    "\n",
    "*Hint: If $I(i,j)$'s domain is [0,255] then $C=1$ if the domain is [0,1] then $C=1/255$.* \n",
    "\n",
    "To calculate the locally normalized luminance, also known as mean substracted contrast normalized (MSCN) coefficients, first, we need to calculate the local mean\n",
    "\n",
    "$$\\mu(i,j) = \\sum_{k=-K}^{K}\\sum_{l=-L}^{L}w_{k,l}I_{k,l}(i,j)$$\n",
    "\n",
    "where $w$ is a Gaussian kernel of size (K, L).\n",
    "\n",
    "The way that the author displays the local mean could be a little bit confusing but it is just applying a Gaussian filter to the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def normalize_kernel(kernel):\n",
    "    return kernel / np.sum(kernel)\n",
    "\n",
    "def gaussian_kernel2d(n, sigma):\n",
    "    Y, X = np.indices((n, n)) - int(n/2)\n",
    "    gaussian_kernel = 1 / (2 * np.pi * sigma ** 2) * np.exp(-(X ** 2 + Y ** 2) / (2 * sigma ** 2)) \n",
    "    return normalize_kernel(gaussian_kernel)\n",
    "\n",
    "def local_mean(image, kernel):\n",
    "    return signal.convolve2d(image, kernel, 'same')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we calculate the local deviation\n",
    "\n",
    "$$ \\sigma(i,j) = \\sqrt{\\sum_{k=-K}^{K}\\sum_{l=-L}^{L}w_{k,l}(I_{k,l}(i, j) - \\mu(i, j))^2 } $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def local_deviation(image, local_mean, kernel):\n",
    "    \"Vectorized approximation of local deviation\"\n",
    "    sigma = image ** 2\n",
    "    sigma = signal.convolve2d(sigma, kernel, 'same')\n",
    "    return np.sqrt(np.abs(local_mean ** 2 - sigma))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we calculate the MSCN coefficients\n",
    "\n",
    "$$\\hat{I}(i,j) = \\frac{I(i,j) - \\mu(i,j)}{\\sigma(i,j) + C}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def calculate_mscn_coefficients(image, kernel_size=6, sigma=7/6):\n",
    "    C = 1/255\n",
    "    kernel = gaussian_kernel2d(kernel_size, sigma=sigma)\n",
    "    local_mean = signal.convolve2d(image, kernel, 'same')\n",
    "    local_var = local_deviation(image, local_mean, kernel)\n",
    "    \n",
    "    return (image - local_mean) / (local_var + C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The author found that the MSCN coefficients are distributed as a Generalized Gaussian Distribution (GGD) for a broader spectrum of distorted image.\n",
    "\n",
    "$$f(x; \\alpha, \\sigma^2) = \\frac{\\alpha}{2\\beta\\Gamma(1/\\alpha)}e^{-\\big(\\frac{|x|}{\\beta}\\big)^\\alpha}$$\n",
    "\n",
    "where\n",
    "\n",
    "$$\\beta = \\sigma \\sqrt{\\frac{\\Gamma\\big(\\frac{1}{\\alpha}\\big)}{\\Gamma\\big(\\frac{3}{\\alpha}\\big)}}$$\n",
    "\n",
    "and $\\Gamma$ is the gamma function.\n",
    "\n",
    "The shape $\\alpha$ controls the shape and $\\sigma^2$ th variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def generalized_gaussian_dist(x, alpha, sigma):\n",
    "    beta = sigma * np.sqrt(special.gamma(1 / alpha) / special.gamma(3 / alpha))\n",
    "    \n",
    "    coefficient = alpha / (2 * beta() * special.gamma(1 / alpha))\n",
    "    return coefficient * np.exp(-(np.abs(x) / beta) ** alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pairwise products of neighboring MSCN coefficients\n",
    "\n",
    "The signs of adjacent coefficients also exhibit a regular structure, which gets disturbed in the presence of distortion. The author proposes the model of pairwise products of neighboring MSCN coefficients along four directions (1) horizontal $H$, (2) vertical $V$, (3) main-diagonal $D1$ and (4) secondary-diagonal $D2$.\n",
    "\n",
    "$$H(i,j) = \\hat{I}(i,j) \\hat{I}(i, j + 1)$$\n",
    "$$V(i,j) = \\hat{I}(i,j) \\hat{I}(i + 1, j)$$\n",
    "$$D1(i,j) = \\hat{I}(i,j) \\hat{I}(i + 1, j + 1)$$\n",
    "$$D2(i,j) = \\hat{I}(i,j) \\hat{I}(i + 1, j - 1)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def calculate_pair_product_coefficients(mscn_coefficients):\n",
    "    return collections.OrderedDict({\n",
    "        'mscn': mscn_coefficients,\n",
    "        'horizontal': mscn_coefficients[:, :-1] * mscn_coefficients[:, 1:],\n",
    "        'vertical': mscn_coefficients[:-1, :] * mscn_coefficients[1:, :],\n",
    "        'main_diagonal': mscn_coefficients[:-1, :-1] * mscn_coefficients[1:, 1:],\n",
    "        'secondary_diagonal': mscn_coefficients[1:, :-1] * mscn_coefficients[:-1, 1:]\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The author mentions that the Generalized Gaussian Distribution does not provide good fit to the empirical histograms of coefficient producs. Thus, they propose the Asymmetric Generalized Gaussian Distribution (AGGD) model [5].\n",
    "\n",
    "$$\n",
    "f(x; \\nu, \\sigma_l^2, \\sigma_r^2) =  \n",
    "   \\begin{cases} \n",
    "      \\frac{\\nu}{(\\beta_l + \\beta_r)\\Gamma\\big(\\frac{1}{\\nu}\\big)}e^{\\big(-\\big(\\frac{-x}{\\beta_l}\\big)^\\nu\\big)} & x < 0 \\\\\n",
    "        \\frac{\\nu}{(\\beta_l + \\beta_r)\\Gamma\\big(\\frac{1}{\\nu}\\big)}e^{\\big(-\\big(\\frac{x}{\\beta_r}\\big)^\\nu\\big)} & x >= 0\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "$$\\beta_{side} = \\sigma_{side} \\sqrt{\\frac{\\Gamma\\big(\\frac{1}{\\nu}\\big)}{\\Gamma\\big(\\frac{3}{\\nu}\\big)}}$$\n",
    "\n",
    "and $side$ can be either $r$ or $l$.\n",
    "\n",
    "Another parameter that is not reflected in the previous formula is the mean\n",
    "\n",
    "$$\\eta = (\\beta_r - beta_l) \\frac{\\Gamma\\big(\\frac{2}{\\nu}\\big)}{\\Gamma\\big(\\frac{1}{\\nu}\\big)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def asymmetric_generalized_gaussian(x, nu, sigma_l, sigma_r):\n",
    "    def beta(sigma):\n",
    "        return sigma * np.sqrt(special.gamma(1 / nu) / special.gamma(3 / nu))\n",
    "    \n",
    "    coefficient = nu / ((beta(sigma_l) + beta(sigma_r)) * special.gamma(1 / nu))\n",
    "    f = lambda x, sigma: coefficient * np.exp(-(x / beta(sigma)) ** nu)\n",
    "        \n",
    "    return np.where(x < 0, f(-x, sigma_l), f(x, sigma_r))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting Asymmetric Generalized Gaussian Distribution\n",
    "\n",
    "The methodology to fit an Asymmetric Generalized Gaussian Distribution is described in [5].\n",
    "\n",
    "1. Calculate $\\hat{\\gamma}$ where $N_l$ is the number of negative samples and $N_r$ is the number of positive samples. \n",
    "\n",
    "$$\n",
    "\\hat{\\gamma} = \\frac{\\sqrt{\\frac{1}{N_l - 1}\\sum_{k=1, x_k < 0}^{N_l} x_k^2}\n",
    "}{\\sqrt{\\frac{1}{N_r - 1}\\sum_{k=1, x_k >= 0}^{N_r} x_k^2}\n",
    "}\n",
    "$$\n",
    "\n",
    "2. Calculate $\\hat{r}$.\n",
    "\n",
    "$$\\hat{r} = \\frac{\\big(\\frac{\\sum|x_k|}{N_l + N_r}\\big)^2}{\\frac{\\sum{x_k ^ 2}}{N_l + N_r}} $$\n",
    "\n",
    "3. Calculate $\\hat{R}$ using $\\hat{\\gamma}$ and $\\hat{r}$ estimations.\n",
    "\n",
    "$$\\hat{R} = \\hat{r} \\frac{(\\hat{\\gamma}^3 + 1)(\\hat{\\gamma} + 1)}{(\\hat{\\gamma}^2 + 1)^2}$$\n",
    "\n",
    "4. Estimate $\\alpha$ using the approximation of the inverse generalized Gaussian ratio.\n",
    "\n",
    "$$\\hat{\\alpha} = \\hat{\\rho} ^ {-1}(\\hat{R})$$\n",
    "\n",
    "$$\\rho(\\alpha) = \\frac{\\Gamma(2 / \\alpha) ^ 2}{\\Gamma(1 / \\alpha) \\Gamma(3 / \\alpha)}$$\n",
    "\n",
    "5. Estimate left and right scale parameters.\n",
    "$$\\sigma_l = \\sqrt{\\frac{1}{N_l - 1}\\sum_{k=1, x_k < 0}^{N_l} x_k^2}$$\n",
    "$$\\sigma_r = \\sqrt{\\frac{1}{N_r - 1}\\sum_{k=1, x_k >= 0}^{N_r} x_k^2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def asymmetric_generalized_gaussian_fit(x):\n",
    "    def estimate_phi(alpha):\n",
    "        numerator = special.gamma(2 / alpha) ** 2\n",
    "        denominator = special.gamma(1 / alpha) * special.gamma(3 / alpha)\n",
    "        return numerator / denominator\n",
    "\n",
    "    def estimate_r_hat(x):\n",
    "        size = np.prod(x.shape)\n",
    "        return (np.sum(np.abs(x)) / size) ** 2 / (np.sum(x ** 2) / size)\n",
    "\n",
    "    def estimate_R_hat(r_hat, gamma):\n",
    "        numerator = (gamma ** 3 + 1) * (gamma + 1)\n",
    "        denominator = (gamma ** 2 + 1) ** 2\n",
    "        return r_hat * numerator / denominator\n",
    "\n",
    "    def mean_squares_sum(x, filter = lambda z: z == z):\n",
    "        filtered_values = x[filter(x)]\n",
    "        squares_sum = np.sum(filtered_values ** 2)\n",
    "        return squares_sum / ((filtered_values.shape))\n",
    "\n",
    "    def estimate_gamma(x):\n",
    "        left_squares = mean_squares_sum(x, lambda z: z < 0)\n",
    "        right_squares = mean_squares_sum(x, lambda z: z >= 0)\n",
    "\n",
    "        return np.sqrt(left_squares) / np.sqrt(right_squares)\n",
    "\n",
    "    def estimate_alpha(x):\n",
    "        r_hat = estimate_r_hat(x)\n",
    "        gamma = estimate_gamma(x)\n",
    "        R_hat = estimate_R_hat(r_hat, gamma)\n",
    "\n",
    "        solution = optimize.root(lambda z: estimate_phi(z) - R_hat, [0.2]).x\n",
    "\n",
    "        return solution[0]\n",
    "\n",
    "    def estimate_sigma(x, alpha, filter = lambda z: z < 0):\n",
    "        return np.sqrt(mean_squares_sum(x, filter))\n",
    "    \n",
    "    def estimate_mean(alpha, sigma_l, sigma_r):\n",
    "        return (sigma_r - sigma_l) * constant * (special.gamma(2 / alpha) / special.gamma(1 / alpha))\n",
    "    \n",
    "    alpha = estimate_alpha(x)\n",
    "    sigma_l = estimate_sigma(x, alpha, lambda z: z < 0)\n",
    "    sigma_r = estimate_sigma(x, alpha, lambda z: z >= 0)\n",
    "    \n",
    "    constant = np.sqrt(special.gamma(1 / alpha) / special.gamma(3 / alpha))\n",
    "    mean = estimate_mean(alpha, sigma_l, sigma_r)\n",
    "    \n",
    "    return alpha, mean, sigma_l, sigma_r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate BRISQUE features\n",
    "\n",
    "The features needed to calculate the image quality are the result of fitting the MSCN coefficients and shifted products to the Generalized Gaussian Distributions. First, we need to fit the MSCN coefficients to the GDD, then the pairwise products to the AGGD. A summary of the features is the following:\n",
    "\n",
    "| Feature ID      | Feature Description                            | Computation Procedure            |\n",
    "|-----------------|------------------------------------------------|----------------------------------|\n",
    "| $f_1-f_2$       | Shape and variance                             | Fit GGD to MSCN coefficients     |\n",
    "| $f_3-f_6$       | Shape, mean, left variance, right variance     | Fit AGGD to H pairwise products  |\n",
    "| $f_7-f_{10}$    | Shape, mean, left variance, right variance     | Fit AGGD to V pairwise products  |\n",
    "| $f_{11}-f_{14}$ | Shape, mean, left variance, right variance     | Fit AGGD to D1 pairwise products |\n",
    "| $f_{15}-f_{18}$ | Shape, mean, left variance, right variance     | Fit AGGD to D2 pairwise products |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def calculate_brisque_features(image, kernel_size=7, sigma=7/6):\n",
    "    def calculate_features(coefficients_name, coefficients, accum=np.array([])):\n",
    "        alpha, mean, sigma_l, sigma_r = asymmetric_generalized_gaussian_fit(coefficients)\n",
    "\n",
    "        if coefficients_name == 'mscn':\n",
    "            var = (sigma_l ** 2 + sigma_r ** 2) / 2\n",
    "            return [alpha, var]\n",
    "        \n",
    "        return [alpha, mean, sigma_l ** 2, sigma_r ** 2]\n",
    "    \n",
    "    mscn_coefficients = calculate_mscn_coefficients(image, kernel_size, sigma)\n",
    "    coefficients = calculate_pair_product_coefficients(mscn_coefficients)\n",
    "    \n",
    "    features = [calculate_features(name, coeff) for name, coeff in coefficients.items()]\n",
    "    flatten_features = list(chain.from_iterable(features))\n",
    "    return np.array(flatten_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hands-on\n",
    "\n",
    "After creating all the functions needed to calculate the brisque features, we can estimate the image quality for a given image. In [4], they use an image that comes from the Kodak dataset [6]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auxiliary Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def load_image(url):\n",
    "    image_stream = request.urlopen(url)\n",
    "    return skimage.io.imread(image_stream, plugin='pil')\n",
    "\n",
    "def plot_histogram(x, label):\n",
    "    n, bins = np.histogram(x.ravel(), bins=50)\n",
    "    n = n / np.max(n)\n",
    "    plt.plot(bins[:-1], n, label=label, marker='o')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "I/O operation on closed file.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-d0eda80dfc8b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'http://www.cs.albany.edu/~xypan/research/img/Kodak/kodim05.png'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mgray_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mskimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrgb2gray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-afed6c1b8816>\u001b[0m in \u001b[0;36mload_image\u001b[0;34m(url)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mimage_stream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mskimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_stream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplugin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'pil'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mplot_histogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/MD_CompressedWavelet-hNaDaTZF/lib/python3.8/site-packages/skimage/io/_io.py\u001b[0m in \u001b[0;36mimread\u001b[0;34m(fname, as_gray, plugin, **plugin_args)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mfile_or_url_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_plugin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'imread'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplugin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplugin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mplugin_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ndim'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/MD_CompressedWavelet-hNaDaTZF/lib/python3.8/site-packages/skimage/io/manage_plugins.py\u001b[0m in \u001b[0;36mcall_plugin\u001b[0;34m(kind, *args, **kwargs)\u001b[0m\n\u001b[1;32m    208\u001b[0m                                (plugin, kind))\n\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/MD_CompressedWavelet-hNaDaTZF/lib/python3.8/site-packages/skimage/io/_plugins/pil_plugin.py\u001b[0m in \u001b[0;36mimread\u001b[0;34m(fname, dtype, img_num, **kwargs)\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpil_to_ndarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimg_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/MD_CompressedWavelet-hNaDaTZF/lib/python3.8/site-packages/skimage/io/_plugins/pil_plugin.py\u001b[0m in \u001b[0;36mpil_to_ndarray\u001b[0;34m(image, dtype, img_num)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mEOFError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/MD_CompressedWavelet-hNaDaTZF/lib/python3.8/site-packages/PIL/PngImagePlugin.py\u001b[0m in \u001b[0;36mseek\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m    746\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__frame\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 748\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_seek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    749\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mEOFError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlast_frame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/MD_CompressedWavelet-hNaDaTZF/lib/python3.8/site-packages/PIL/PngImagePlugin.py\u001b[0m in \u001b[0;36m_seek\u001b[0;34m(self, frame, rewind)\u001b[0m\n\u001b[1;32m    782\u001b[0m         \u001b[0;31m# advance to the next frame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    783\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__prepare_idat\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 784\u001b[0;31m             \u001b[0mImageFile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_safe_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__prepare_idat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    785\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__prepare_idat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m         \u001b[0mframe_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/MD_CompressedWavelet-hNaDaTZF/lib/python3.8/site-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36m_safe_read\u001b[0;34m(fp, size)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34mb\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mSAFEBLOCK\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: I/O operation on closed file."
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.figsize\"] = 12, 9\n",
    "\n",
    "url = 'http://www.cs.albany.edu/~xypan/research/img/Kodak/kodim05.png'\n",
    "image = load_image(url)\n",
    "gray_image = skimage.color.rgb2gray(image)\n",
    "\n",
    "_ = skimage.io.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Calculate Coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "mscn_coefficients = calculate_mscn_coefficients(gray_image, 7, 7/6)\n",
    "coefficients = calculate_pair_product_coefficients(mscn_coefficients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After calculating the MSCN coefficients and the pairwise products, we can verify that the distributions are in fact different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.figsize\"] = 12, 11\n",
    "\n",
    "for name, coeff in coefficients.items():\n",
    "    plot_histogram(coeff.ravel(), name)\n",
    "\n",
    "plt.axis([-2.5, 2.5, 0, 1.05])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Fit Coefficients to Generalized Gaussian Distributions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "brisque_features = calculate_brisque_features(gray_image, kernel_size=7, sigma=7/6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Resize Image and Calculate BRISQUE Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "downscaled_image = cv2.resize(gray_image, None, fx=1/2, fy=1/2, interpolation = cv2.INTER_CUBIC)\n",
    "downscale_brisque_features = calculate_brisque_features(downscaled_image, kernel_size=7, sigma=7/6)\n",
    "\n",
    "brisque_features = np.concatenate((brisque_features, downscale_brisque_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Scale Features and Feed the SVR\n",
    "The author provides a pretrained SVR model to calculate the quality assessment. However, in order to have good results, we need to scale the features to [-1, 1]. For the latter, we need the same parameters the author used to scale the features vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def scale_features(features):\n",
    "    with open('normalize.pickle', 'rb') as handle:\n",
    "        scale_params = pickle.load(handle)\n",
    "    \n",
    "    min_ = np.array(scale_params['min_'])\n",
    "    max_ = np.array(scale_params['max_'])\n",
    "    \n",
    "    return -1 + (2.0 / (max_ - min_) * (features - min_))\n",
    "\n",
    "def calculate_image_quality_score(brisque_features):\n",
    "    model = svmutil.svm_load_model('brisque_svm.txt')\n",
    "    scaled_brisque_features = scale_features(brisque_features)\n",
    "    \n",
    "    x, idx = svmutil.gen_svm_nodearray(\n",
    "        scaled_brisque_features,\n",
    "        isKernel=(model.param.kernel_type == svmutil.PRECOMPUTED))\n",
    "    \n",
    "    nr_classifier = 1\n",
    "    prob_estimates = (svmutil.c_double * nr_classifier)()\n",
    "    \n",
    "    return svmutil.libsvm.svm_predict_probability(model, x, prob_estimates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scaled used to represent image quality goes from 0 to 100. An image quality of 100 means that the image's quality is very bad. In the case of the analyzed image, we get that it is a good quality image. It makes sense because we are using the reference image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "calculate_image_quality_score(brisque_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This method was tested with the TID2008 database and performs well; even compared with referenced IQA methods. Although, the future work is to check the performance of other machine learning algorithms like XGBoost, LightGBM, for the pattern recognition step.\n",
    "\n",
    "## References\n",
    "\n",
    "[1] Maître, H. (2017). From Photon to pixel: the digital camera handbook. John Wiley & Sons.\n",
    "\n",
    "[2] Wang, Z., Bovik, A. C., Sheikh, H. R., & Simoncelli, E. P. (2004). Image quality assessment: from error visibility to structural similarity. IEEE transactions on image processing, 13(4), 600-612.\n",
    "\n",
    "[3] Ponomarenko, N., Lukin, V., Zelensky, A., Egiazarian, K., Carli, M., & Battisti, F. (2009). TID2008-a database for evaluation of full-reference visual quality assessment metrics. Advances of Modern Radioelectronics, 10(4), 30-45.\n",
    "\n",
    "[4] Mittal, A., Moorthy, A. K., & Bovik, A. C. (2012). No-reference image quality assessment in the spatial domain. IEEE Transactions on Image Processing, 21(12), 4695-4708.\n",
    "\n",
    "[5] Lasmar, N. E., Stitou, Y., & Berthoumieu, Y. (2009). Multiscale skewed heavy-tailed model for texture analysis. Proceedings - International Conference on Image Processing, ICIP, (1), 2281–2284."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
